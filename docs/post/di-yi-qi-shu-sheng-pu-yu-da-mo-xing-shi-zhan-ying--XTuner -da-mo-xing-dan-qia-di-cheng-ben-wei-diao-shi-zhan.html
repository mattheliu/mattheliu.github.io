<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    
    <link rel="icon" href="https://github.githubassets.com/favicons/favicon.svg"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="> æ€ä¹ˆç¡•å‘¢ï¼Œç¥å¤§å®¶ç‚¼ä¸¹æ„‰å¿«å§~ ğŸ˜™

## 1 æ¦‚è¿°

### 1.1 XTuner

ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒå·¥å…·ç®±ã€‚">
<meta property="og:title" content="ç¬¬ä¸€æœŸä¹¦ç”Ÿæµ¦è¯­å¤§æ¨¡å‹å®æˆ˜è¥-XTuner å¤§æ¨¡å‹å•å¡ä½æˆæœ¬å¾®è°ƒå®æˆ˜">
<meta property="og:description" content="> æ€ä¹ˆç¡•å‘¢ï¼Œç¥å¤§å®¶ç‚¼ä¸¹æ„‰å¿«å§~ ğŸ˜™

## 1 æ¦‚è¿°

### 1.1 XTuner

ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒå·¥å…·ç®±ã€‚">
<meta property="og:type" content="article">
<meta property="og:url" content="https://mattheliu.github.io/post/di-yi-qi-shu-sheng-pu-yu-da-mo-xing-shi-zhan-ying--XTuner%20-da-mo-xing-dan-qia-di-cheng-ben-wei-diao-shi-zhan.html">
<meta property="og:image" content="https://github.githubassets.com/favicons/favicon.svg">
<title>ç¬¬ä¸€æœŸä¹¦ç”Ÿæµ¦è¯­å¤§æ¨¡å‹å®æˆ˜è¥-XTuner å¤§æ¨¡å‹å•å¡ä½æˆæœ¬å¾®è°ƒå®æˆ˜</title>
<link href="//unpkg.com/@wooorm/starry-night@2.1.1/style/both.css" rel="stylesheet" />


</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}
.copy-feedback {
    display: none;
    position: absolute;
    top: 10px;
    right: 50px;
    color: var(--color-fg-on-emphasis);
    background-color: var(--color-fg-muted);
    border-radius: 3px;
    padding: 5px 8px;
    font-size: 12px;
}
</style>




<body>
    <div id="header">
<h1 class="postTitle">ç¬¬ä¸€æœŸä¹¦ç”Ÿæµ¦è¯­å¤§æ¨¡å‹å®æˆ˜è¥-XTuner å¤§æ¨¡å‹å•å¡ä½æˆæœ¬å¾®è°ƒå®æˆ˜</h1>
<div class="title-right">
    <a href="https://mattheliu.github.io" id="buttonHome" class="btn btn-invisible circle" title="é¦–é¡µ">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/mattheliu/mattheliu.github.io/issues/4" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="åˆ‡æ¢ä¸»é¢˜">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><blockquote>
<p>æ€ä¹ˆç¡•å‘¢ï¼Œç¥å¤§å®¶ç‚¼ä¸¹æ„‰å¿«å§~ ğŸ˜™</p>
</blockquote>
<h2>1 æ¦‚è¿°</h2>
<h3>1.1 XTuner</h3>
<p>ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒå·¥å…·ç®±ã€‚<em>ç”±</em> <em>MMRazor</em> <em>å’Œ</em> <em>MMDeploy</em> <em>è”åˆå¼€å‘ã€‚</em></p>
<h3>1.2 æ”¯æŒçš„å¼€æºLLM (2023.11.01)</h3>
<ul>
<li><strong><a href="https://huggingface.co/internlm/internlm-7b" rel="nofollow">InternLM</a></strong> âœ…</li>
<li><a href="https://huggingface.co/meta-llama" rel="nofollow">Llamaï¼ŒLlama2</a></li>
<li><a href="https://huggingface.co/THUDM/chatglm2-6b" rel="nofollow">ChatGLM2</a>ï¼Œ<a href="https://huggingface.co/THUDM/chatglm3-6b-base" rel="nofollow">ChatGLM3</a></li>
<li><a href="https://huggingface.co/Qwen/Qwen-7B" rel="nofollow">Qwen</a></li>
<li><a href="https://huggingface.co/baichuan-inc/Baichuan-7B" rel="nofollow">Baichuan</a>ï¼Œ<a href="https://huggingface.co/baichuan-inc/Baichuan2-7B-Base" rel="nofollow">Baichuan2</a></li>
<li>......</li>
<li><a href="https://huggingface.co/HuggingFaceH4/zephyr-7b-beta" rel="nofollow">Zephyr</a></li>
</ul>
<h3>1.3 ç‰¹è‰²</h3>
<ul>
<li>ğŸ¤“ <strong>å‚»ç“œåŒ–ï¼š</strong> ä»¥ é…ç½®æ–‡ä»¶ çš„å½¢å¼å°è£…äº†å¤§éƒ¨åˆ†å¾®è°ƒåœºæ™¯ï¼Œ<strong>0åŸºç¡€çš„éä¸“ä¸šäººå‘˜ä¹Ÿèƒ½ä¸€é”®å¼€å§‹å¾®è°ƒ</strong>ã€‚</li>
<li>ğŸƒ <strong>è½»é‡çº§ï¼š</strong> å¯¹äº 7B å‚æ•°é‡çš„LLMï¼Œ<strong>å¾®è°ƒæ‰€éœ€çš„æœ€å°æ˜¾å­˜ä»…ä¸º 8GB</strong> ï¼š <strong>æ¶ˆè´¹çº§æ˜¾å¡âœ…ï¼Œcolabâœ…</strong></li>
</ul>
<h3>1.4 å¾®è°ƒåŸç†</h3>
<blockquote>
<p>æƒ³è±¡ä¸€ä¸‹ï¼Œä½ æœ‰ä¸€ä¸ªè¶…å¤§çš„ç©å…·ï¼Œç°åœ¨ä½ æƒ³æ”¹é€ è¿™ä¸ªè¶…å¤§çš„ç©å…·ã€‚ä½†æ˜¯ï¼Œ<strong>å¯¹æ•´ä¸ªç©å…·è¿›è¡Œå…¨é¢çš„æ”¹åŠ¨ä¼šéå¸¸æ˜‚è´µ</strong>ã€‚</p>
</blockquote>
<p>â€» å› æ­¤ï¼Œä½ æ‰¾åˆ°äº†ä¸€ç§å« <strong>LoRA</strong> çš„æ–¹æ³•ï¼š<strong>åªå¯¹ç©å…·ä¸­çš„æŸäº›é›¶ä»¶è¿›è¡Œæ”¹åŠ¨ï¼Œè€Œä¸æ˜¯å¯¹æ•´ä¸ªç©å…·è¿›è¡Œå…¨é¢æ”¹åŠ¨</strong>ã€‚</p>
<p>â€» è€Œ <strong>QLoRA</strong> æ˜¯ LoRA çš„ä¸€ç§æ”¹è¿›ï¼šå¦‚æœä½ æ‰‹é‡Œåªæœ‰ä¸€æŠŠç”Ÿé”ˆçš„èºä¸åˆ€ï¼Œä¹Ÿèƒ½æ”¹é€ ä½ çš„ç©å…·ã€‚</p>
<ul>
<li><strong>Full</strong> :       ğŸ˜³ â†’ ğŸš²</li>
<li><strong><a href="http://arxiv.org/abs/2106.09685" rel="nofollow">LoRA</a></strong> :     ğŸ˜³ â†’ ğŸ›µ</li>
<li><strong><a href="http://arxiv.org/abs/2305.14314" rel="nofollow">QLoRA</a></strong> :   ğŸ˜³ â†’ ğŸ</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="imgs/cat_fly.png"><img src="imgs/cat_fly.png" alt="WOZJXUtaKlEk9S4.png" style="max-width: 100%;"></a></p>
<h2>2 å¿«é€Ÿä¸Šæ‰‹</h2>
<h3>2.1 å¹³å°</h3>
<p>Ubuntu + Anaconda + CUDA/CUDNN + 8GB nvidiaæ˜¾å¡</p>
<h3>2.2 å®‰è£…</h3>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> å¦‚æœä½ æ˜¯åœ¨ InternStudio å¹³å°ï¼Œåˆ™ä»æœ¬åœ° clone ä¸€ä¸ªå·²æœ‰ pytorch 2.0.1 çš„ç¯å¢ƒï¼š</span>
/root/share/install_conda_env_internlm_base.sh xtuner0.1.9
<span class="pl-c"><span class="pl-c">#</span> å¦‚æœä½ æ˜¯åœ¨å…¶ä»–å¹³å°ï¼š</span>
conda create --name xtuner0.1.9 python=3.10 -y

<span class="pl-c"><span class="pl-c">#</span> æ¿€æ´»ç¯å¢ƒ</span>
conda activate xtuner0.1.9
<span class="pl-c"><span class="pl-c">#</span> è¿›å…¥å®¶ç›®å½• ï¼ˆ~çš„æ„æ€æ˜¯ â€œå½“å‰ç”¨æˆ·çš„homeè·¯å¾„â€ï¼‰</span>
<span class="pl-c1">cd</span> <span class="pl-k">~</span>
<span class="pl-c"><span class="pl-c">#</span> åˆ›å»ºç‰ˆæœ¬æ–‡ä»¶å¤¹å¹¶è¿›å…¥ï¼Œä»¥è·Ÿéšæœ¬æ•™ç¨‹</span>
mkdir xtuner019 <span class="pl-k">&amp;&amp;</span> <span class="pl-c1">cd</span> xtuner019


<span class="pl-c"><span class="pl-c">#</span> æ‹‰å– 0.1.9 çš„ç‰ˆæœ¬æºç </span>
git clone -b v0.1.9  https://github.com/InternLM/xtuner
<span class="pl-c"><span class="pl-c">#</span> æ— æ³•è®¿é—®githubçš„ç”¨æˆ·è¯·ä» gitee æ‹‰å–:</span>
<span class="pl-c"><span class="pl-c">#</span> git clone -b v0.1.9 https://gitee.com/Internlm/xtuner</span>

<span class="pl-c"><span class="pl-c">#</span> è¿›å…¥æºç ç›®å½•</span>
<span class="pl-c1">cd</span> xtuner

<span class="pl-c"><span class="pl-c">#</span> ä»æºç å®‰è£… XTuner</span>
pip install -e <span class="pl-s"><span class="pl-pds">'</span>.[all]<span class="pl-pds">'</span></span></pre></div>
<p>å®‰è£…å®Œåï¼Œå°±å¼€å§‹ææå‡†å¤‡å·¥ä½œäº†ã€‚ï¼ˆå‡†å¤‡åœ¨ oasst1 æ•°æ®é›†ä¸Šå¾®è°ƒ internlm-7b-chatï¼‰</p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> åˆ›å»ºä¸€ä¸ªå¾®è°ƒ oasst1 æ•°æ®é›†çš„å·¥ä½œè·¯å¾„ï¼Œè¿›å…¥</span>
mkdir <span class="pl-k">~</span>/ft-oasst1 <span class="pl-k">&amp;&amp;</span> <span class="pl-c1">cd</span> <span class="pl-k">~</span>/ft-oasst1</pre></div>
<h3>2.3 å¾®è°ƒ</h3>
<h4>2.3.1 å‡†å¤‡é…ç½®æ–‡ä»¶</h4>
<p>XTuner æä¾›å¤šä¸ªå¼€ç®±å³ç”¨çš„é…ç½®æ–‡ä»¶ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ä¸‹åˆ—å‘½ä»¤æŸ¥çœ‹ï¼š</p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> åˆ—å‡ºæ‰€æœ‰å†…ç½®é…ç½®</span>
xtuner list-cfg</pre></div>
<blockquote>
<p>å‡å¦‚æ˜¾ç¤ºbash: xtuner: command not foundçš„è¯å¯ä»¥è€ƒè™‘åœ¨ç»ˆç«¯è¾“å…¥ export PATH=$PATH:'/root/.local/bin'</p>
</blockquote>
<p><a target="_blank" rel="noopener noreferrer" href="imgs/cfgs.png"><img src="imgs/cfgs.png" alt="QCgmlv1VpU3fZPk.png" style="max-width: 100%;"></a></p>
<p>æ‹·è´ä¸€ä¸ªé…ç½®æ–‡ä»¶åˆ°å½“å‰ç›®å½•ï¼š<br>
<code class="notranslate"># xtuner copy-cfg ${CONFIG_NAME} ${SAVE_PATH}</code></p>
<p>åœ¨æœ¬æ¡ˆä¾‹ä¸­å³ï¼šï¼ˆæ³¨æ„æœ€åæœ‰ä¸ªè‹±æ–‡å¥å·ï¼Œä»£è¡¨å¤åˆ¶åˆ°å½“å‰è·¯å¾„ï¼‰</p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c1">cd</span> <span class="pl-k">~</span>/ft-oasst1
xtuner copy-cfg internlm_chat_7b_qlora_oasst1_e3 <span class="pl-c1">.</span></pre></div>
<p>é…ç½®æ–‡ä»¶åçš„è§£é‡Šï¼š</p>
<blockquote>
<p>xtuner copy-cfg internlm_chat_7b_qlora_oasst1_e3 .</p>
</blockquote>
<markdown-accessiblity-table><table role="table">
<thead>
<tr>
<th>æ¨¡å‹å</th>
<th>internlm_chat_7b</th>
</tr>
</thead>
<tbody>
<tr>
<td>ä½¿ç”¨ç®—æ³•</td>
<td>qlora</td>
</tr>
<tr>
<td>æ•°æ®é›†</td>
<td>oasst1</td>
</tr>
<tr>
<td>æŠŠæ•°æ®é›†è·‘å‡ æ¬¡</td>
<td>è·‘3æ¬¡ï¼še3 (epoch 3 )</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p>*æ—  chatæ¯”å¦‚ <code class="notranslate">internlm-7b</code> ä»£è¡¨æ˜¯åŸºåº§(base)æ¨¡å‹</p>
<h4>2.3.2 æ¨¡å‹ä¸‹è½½</h4>
<blockquote>
<p>ç”±äºä¸‹è½½æ¨¡å‹å¾ˆæ…¢ï¼Œç”¨æ•™å­¦å¹³å°çš„åŒå­¦å¯ä»¥ç›´æ¥å¤åˆ¶æ¨¡å‹ã€‚</p>
</blockquote>
<div class="highlight highlight-source-shell"><pre class="notranslate">cp -r /root/share/temp/model_repos/internlm-chat-7b <span class="pl-k">~</span>/ft-oasst1/</pre></div>
<blockquote>
<p>ä»¥ä¸‹æ˜¯è‡ªå·±ä¸‹è½½æ¨¡å‹çš„æ­¥éª¤ã€‚</p>
</blockquote>
<p>ä¸ç”¨ xtuner é»˜è®¤çš„<code class="notranslate">ä» huggingface æ‹‰å–æ¨¡å‹</code>ï¼Œè€Œæ˜¯æå‰ä» <del>OpenXLab</del> ModelScope ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°</p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> åˆ›å»ºä¸€ä¸ªç›®å½•ï¼Œæ”¾æ¨¡å‹æ–‡ä»¶ï¼Œé˜²æ­¢æ•£è½ä¸€åœ°</span>
mkdir <span class="pl-k">~</span>/ft-oasst1/internlm-chat-7b

<span class="pl-c"><span class="pl-c">#</span> è£…ä¸€ä¸‹æ‹‰å–æ¨¡å‹æ–‡ä»¶è¦ç”¨çš„åº“</span>
pip install modelscope

<span class="pl-c"><span class="pl-c">#</span> ä» modelscope ä¸‹è½½ä¸‹è½½æ¨¡å‹æ–‡ä»¶</span>
<span class="pl-c1">cd</span> <span class="pl-k">~</span>/ft-oasst1
apt install git git-lfs -y
git lfs install
git lfs clone https://modelscope.cn/Shanghai_AI_Laboratory/internlm-chat-7b.git -b v1.0.3</pre></div>
<h4>2.3.3 æ•°æ®é›†ä¸‹è½½</h4>
<blockquote>
<p><a href="https://huggingface.co/datasets/timdettmers/openassistant-guanaco/tree/main" rel="nofollow">https://huggingface.co/datasets/timdettmers/openassistant-guanaco/tree/main</a></p>
</blockquote>
<p>ç”±äº huggingface ç½‘ç»œé—®é¢˜ï¼Œå’±ä»¬å·²ç»ç»™å¤§å®¶æå‰ä¸‹è½½å¥½äº†ï¼Œå¤åˆ¶åˆ°æ­£ç¡®ä½ç½®å³å¯ï¼š</p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c1">cd</span> <span class="pl-k">~</span>/ft-oasst1
<span class="pl-c"><span class="pl-c">#</span> ...-guanaco åé¢æœ‰ä¸ªç©ºæ ¼å’Œè‹±æ–‡å¥å·å•Š</span>
cp -r /root/share/temp/datasets/openassistant-guanaco <span class="pl-c1">.</span></pre></div>
<p>æ­¤æ—¶ï¼Œå½“å‰è·¯å¾„çš„æ–‡ä»¶åº”è¯¥é•¿è¿™æ ·ï¼š</p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-k">|</span>-- internlm-chat-7b
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- README.md
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- config.json
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- configuration.json
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- configuration_internlm.py
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- generation_config.json
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- modeling_internlm.py
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- pytorch_model-00001-of-00008.bin
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- pytorch_model-00002-of-00008.bin
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- pytorch_model-00003-of-00008.bin
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- pytorch_model-00004-of-00008.bin
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- pytorch_model-00005-of-00008.bin
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- pytorch_model-00006-of-00008.bin
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- pytorch_model-00007-of-00008.bin
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- pytorch_model-00008-of-00008.bin
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- pytorch_model.bin.index.json
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- special_tokens_map.json
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- tokenization_internlm.py
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- tokenizer.model
<span class="pl-k">|</span>   <span class="pl-s"><span class="pl-pds">`</span>-- tokenizer_config.json</span>
<span class="pl-s"><span class="pl-k">|</span>-- internlm_chat_7b_qlora_oasst1_e3_copy.py</span>
<span class="pl-s"><span class="pl-pds">`</span></span>-- openassistant-guanaco
    <span class="pl-k">|</span>-- openassistant_best_replies_eval.jsonl
    <span class="pl-s"><span class="pl-pds">`</span>-- openassistant_best_replies_train.jsonl</span></pre></div>
<h4>2.3.4 ä¿®æ”¹é…ç½®æ–‡ä»¶</h4>
<p>ä¿®æ”¹å…¶ä¸­çš„æ¨¡å‹å’Œæ•°æ®é›†ä¸º æœ¬åœ°è·¯å¾„</p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c1">cd</span> <span class="pl-k">~</span>/ft-oasst1
vim internlm_chat_7b_qlora_oasst1_e3_copy.py</pre></div>
<blockquote>
<p>åœ¨vimç•Œé¢å®Œæˆä¿®æ”¹åï¼Œè¯·è¾“å…¥:wqé€€å‡ºã€‚å‡å¦‚è®¤ä¸ºæ”¹é”™äº†å¯ä»¥ç”¨:q!é€€å‡ºä¸”ä¸ä¿å­˜ã€‚å½“ç„¶æˆ‘ä»¬ä¹Ÿå¯ä»¥è€ƒè™‘æ‰“å¼€pythonæ–‡ä»¶ç›´æ¥ä¿®æ”¹ï¼Œä½†æ³¨æ„ä¿®æ”¹å®Œåéœ€è¦æŒ‰ä¸‹Ctrl+Sè¿›è¡Œä¿å­˜ã€‚</p>
</blockquote>
<p>å‡å·ä»£è¡¨è¦åˆ é™¤çš„è¡Œï¼ŒåŠ å·ä»£è¡¨è¦å¢åŠ çš„è¡Œã€‚</p>
<div class="highlight highlight-source-diff"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> ä¿®æ”¹æ¨¡å‹ä¸ºæœ¬åœ°è·¯å¾„</span>
<span class="pl-md"><span class="pl-md">-</span> pretrained_model_name_or_path = 'internlm/internlm-chat-7b'</span>
<span class="pl-mi1"><span class="pl-mi1">+</span> pretrained_model_name_or_path = './internlm-chat-7b'</span>

<span class="pl-c"><span class="pl-c">#</span> ä¿®æ”¹è®­ç»ƒæ•°æ®é›†ä¸ºæœ¬åœ°è·¯å¾„</span>
<span class="pl-md"><span class="pl-md">-</span> data_path = 'timdettmers/openassistant-guanaco'</span>
<span class="pl-mi1"><span class="pl-mi1">+</span> data_path = './openassistant-guanaco'</span></pre></div>
<p><strong>å¸¸ç”¨è¶…å‚</strong></p>
<markdown-accessiblity-table><table role="table">
<thead>
<tr>
<th>å‚æ•°å</th>
<th>è§£é‡Š</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>data_path</strong></td>
<td>æ•°æ®è·¯å¾„æˆ– HuggingFace ä»“åº“å</td>
</tr>
<tr>
<td>max_length</td>
<td>å•æ¡æ•°æ®æœ€å¤§ Token æ•°ï¼Œè¶…è¿‡åˆ™æˆªæ–­</td>
</tr>
<tr>
<td>pack_to_max_length</td>
<td>æ˜¯å¦å°†å¤šæ¡çŸ­æ•°æ®æ‹¼æ¥åˆ° max_lengthï¼Œæé«˜ GPU åˆ©ç”¨ç‡</td>
</tr>
<tr>
<td>accumulative_counts</td>
<td>æ¢¯åº¦ç´¯ç§¯ï¼Œæ¯å¤šå°‘æ¬¡ backward æ›´æ–°ä¸€æ¬¡å‚æ•°</td>
</tr>
<tr>
<td>evaluation_inputs</td>
<td>è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šæ ¹æ®ç»™å®šçš„é—®é¢˜è¿›è¡Œæ¨ç†ï¼Œä¾¿äºè§‚æµ‹è®­ç»ƒçŠ¶æ€</td>
</tr>
<tr>
<td>evaluation_freq</td>
<td>Evaluation çš„è¯„æµ‹é—´éš” iter æ•°</td>
</tr>
<tr>
<td>......</td>
<td>......</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<blockquote>
<p>å¦‚æœæƒ³æŠŠæ˜¾å¡çš„ç°å­˜åƒæ»¡ï¼Œå……åˆ†åˆ©ç”¨æ˜¾å¡èµ„æºï¼Œå¯ä»¥å°† <code class="notranslate">max_length</code> å’Œ <code class="notranslate">batch_size</code> è¿™ä¸¤ä¸ªå‚æ•°è°ƒå¤§ã€‚</p>
</blockquote>
<h4>2.3.5 å¼€å§‹å¾®è°ƒ</h4>
<p><strong>è®­ç»ƒï¼š</strong></p>
<p>xtuner train ${CONFIG_NAME_OR_PATH}</p>
<p><strong>ä¹Ÿå¯ä»¥å¢åŠ  deepspeed è¿›è¡Œè®­ç»ƒåŠ é€Ÿï¼š</strong></p>
<p>xtuner train ${CONFIG_NAME_OR_PATH} --deepspeed deepspeed_zero2</p>
<p>ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ QLoRA ç®—æ³•åœ¨ oasst1 æ•°æ®é›†ä¸Šå¾®è°ƒ InternLM-7Bï¼š</p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> å•å¡</span>
<span class="pl-c"><span class="pl-c">#</span># ç”¨åˆšæ‰æ”¹å¥½çš„configæ–‡ä»¶è®­ç»ƒ</span>
xtuner train ./internlm_chat_7b_qlora_oasst1_e3_copy.py

<span class="pl-c"><span class="pl-c">#</span> å¤šå¡</span>
NPROC_PER_NODE=<span class="pl-smi">${GPU_NUM}</span> xtuner train ./internlm_chat_7b_qlora_oasst1_e3_copy.py

<span class="pl-c"><span class="pl-c">#</span> è‹¥è¦å¼€å¯ deepspeed åŠ é€Ÿï¼Œå¢åŠ  --deepspeed deepspeed_zero2 å³å¯</span></pre></div>
<blockquote>
<p>å¾®è°ƒå¾—åˆ°çš„ PTH æ¨¡å‹æ–‡ä»¶å’Œå…¶ä»–æ‚ä¸ƒæ‚å…«çš„æ–‡ä»¶éƒ½é»˜è®¤åœ¨å½“å‰çš„ <code class="notranslate">./work_dirs</code> ä¸­ã€‚</p>
</blockquote>
<p>è·‘å®Œè®­ç»ƒåï¼Œå½“å‰è·¯å¾„åº”è¯¥é•¿è¿™æ ·ï¼š</p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-k">|</span>-- internlm-chat-7b
<span class="pl-k">|</span>-- internlm_chat_7b_qlora_oasst1_e3_copy.py
<span class="pl-k">|</span>-- openassistant-guanaco
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- openassistant_best_replies_eval.jsonl
<span class="pl-k">|</span>   <span class="pl-s"><span class="pl-pds">`</span>-- openassistant_best_replies_train.jsonl</span>
<span class="pl-s"><span class="pl-pds">`</span></span>-- work_dirs
    <span class="pl-s"><span class="pl-pds">`</span>-- internlm_chat_7b_qlora_oasst1_e3_copy</span>
<span class="pl-s">        <span class="pl-k">|</span>-- 20231101_152923</span>
<span class="pl-s">        <span class="pl-k">|</span>   <span class="pl-k">|</span>-- 20231101_152923.log</span>
<span class="pl-s">        <span class="pl-k">|</span>   <span class="pl-pds">`</span></span>-- vis_data
        <span class="pl-k">|</span>       <span class="pl-k">|</span>-- 20231101_152923.json
        <span class="pl-k">|</span>       <span class="pl-k">|</span>-- config.py
        <span class="pl-k">|</span>       <span class="pl-s"><span class="pl-pds">`</span>-- scalars.json</span>
<span class="pl-s">        <span class="pl-k">|</span>-- epoch_1.pth</span>
<span class="pl-s">        <span class="pl-k">|</span>-- epoch_2.pth</span>
<span class="pl-s">        <span class="pl-k">|</span>-- epoch_3.pth</span>
<span class="pl-s">        <span class="pl-k">|</span>-- internlm_chat_7b_qlora_oasst1_e3_copy.py</span>
<span class="pl-s">        <span class="pl-pds">`</span></span>-- last_checkpoint</pre></div>
<h4>2.3.6 å°†å¾—åˆ°çš„ PTH æ¨¡å‹è½¬æ¢ä¸º HuggingFace æ¨¡å‹ï¼Œ<strong>å³ï¼šç”Ÿæˆ Adapter æ–‡ä»¶å¤¹</strong></h4>
<p><code class="notranslate">xtuner convert pth_to_hf ${CONFIG_NAME_OR_PATH} ${PTH_file_dir} ${SAVE_PATH}</code></p>
<p>åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œä¸ºï¼š</p>
<div class="highlight highlight-source-shell"><pre class="notranslate">mkdir hf
<span class="pl-k">export</span> MKL_SERVICE_FORCE_INTEL=1

xtuner convert pth_to_hf ./internlm_chat_7b_qlora_oasst1_e3_copy.py ./work_dirs/internlm_chat_7b_qlora_oasst1_e3_copy/epoch_1.pth ./hf</pre></div>
<p>æ­¤æ—¶ï¼Œè·¯å¾„ä¸­åº”è¯¥é•¿è¿™æ ·ï¼š</p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-k">|</span>-- internlm-chat-7b
<span class="pl-k">|</span>-- internlm_chat_7b_qlora_oasst1_e3_copy.py
<span class="pl-k">|</span>-- openassistant-guanaco
<span class="pl-k">|</span>   <span class="pl-k">|</span>-- openassistant_best_replies_eval.jsonl
<span class="pl-k">|</span>   <span class="pl-s"><span class="pl-pds">`</span>-- openassistant_best_replies_train.jsonl</span>
<span class="pl-s"><span class="pl-k">|</span>-- hf</span>
<span class="pl-s"><span class="pl-k">|</span>   <span class="pl-k">|</span>-- README.md</span>
<span class="pl-s"><span class="pl-k">|</span>   <span class="pl-k">|</span>-- adapter_config.json</span>
<span class="pl-s"><span class="pl-k">|</span>   <span class="pl-k">|</span>-- adapter_model.bin</span>
<span class="pl-s"><span class="pl-k">|</span>   <span class="pl-pds">`</span></span>-- xtuner_config.py
<span class="pl-s"><span class="pl-pds">`</span>-- work_dirs</span>
<span class="pl-s">    <span class="pl-pds">`</span></span>-- internlm_chat_7b_qlora_oasst1_e3_copy
        <span class="pl-k">|</span>-- 20231101_152923
        <span class="pl-k">|</span>   <span class="pl-k">|</span>-- 20231101_152923.log
        <span class="pl-k">|</span>   <span class="pl-s"><span class="pl-pds">`</span>-- vis_data</span>
<span class="pl-s">        <span class="pl-k">|</span>       <span class="pl-k">|</span>-- 20231101_152923.json</span>
<span class="pl-s">        <span class="pl-k">|</span>       <span class="pl-k">|</span>-- config.py</span>
<span class="pl-s">        <span class="pl-k">|</span>       <span class="pl-pds">`</span></span>-- scalars.json
        <span class="pl-k">|</span>-- epoch_1.pth
        <span class="pl-k">|</span>-- epoch_2.pth
        <span class="pl-k">|</span>-- epoch_3.pth
        <span class="pl-k">|</span>-- internlm_chat_7b_qlora_oasst1_e3_copy.py
        <span class="pl-s"><span class="pl-pds">`</span>-- last_checkpoint</span></pre></div>
<p><span><strong>æ­¤æ—¶ï¼Œhf æ–‡ä»¶å¤¹å³ä¸ºæˆ‘ä»¬å¹³æ—¶æ‰€ç†è§£çš„æ‰€è°“ â€œLoRA æ¨¡å‹æ–‡ä»¶â€</strong></span></p>
<blockquote>
<p>å¯ä»¥ç®€å•ç†è§£ï¼šLoRA æ¨¡å‹æ–‡ä»¶ = Adapter</p>
</blockquote>
<h3>2.4 éƒ¨ç½²ä¸æµ‹è¯•</h3>
<h4>2.4.1 å°† HuggingFace adapter åˆå¹¶åˆ°å¤§è¯­è¨€æ¨¡å‹ï¼š</h4>
<div class="highlight highlight-source-shell"><pre class="notranslate">xtuner convert merge ./internlm-chat-7b ./hf ./merged --max-shard-size 2GB
<span class="pl-c"><span class="pl-c">#</span> xtuner convert merge \</span>
<span class="pl-c"><span class="pl-c">#</span>     ${NAME_OR_PATH_TO_LLM} \</span>
<span class="pl-c"><span class="pl-c">#</span>     ${NAME_OR_PATH_TO_ADAPTER} \</span>
<span class="pl-c"><span class="pl-c">#</span>     ${SAVE_PATH} \</span>
<span class="pl-c"><span class="pl-c">#</span>     --max-shard-size 2GB</span></pre></div>
<h4>2.4.2 ä¸åˆå¹¶åçš„æ¨¡å‹å¯¹è¯ï¼š</h4>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> åŠ è½½ Adapter æ¨¡å‹å¯¹è¯ï¼ˆFloat 16ï¼‰</span>
xtuner chat ./merged --prompt-template internlm_chat

<span class="pl-c"><span class="pl-c">#</span> 4 bit é‡åŒ–åŠ è½½</span>
<span class="pl-c"><span class="pl-c">#</span> xtuner chat ./merged --bits 4 --prompt-template internlm_chat</span></pre></div>
<h4>2.4.3 Demo</h4>
<ul>
<li>ä¿®æ”¹ <code class="notranslate">cli_demo.py</code> ä¸­çš„æ¨¡å‹è·¯å¾„</li>
</ul>
<div class="highlight highlight-source-diff"><pre class="notranslate"><span class="pl-md"><span class="pl-md">-</span> model_name_or_path = "/root/model/Shanghai_AI_Laboratory/internlm-chat-7b"</span>
<span class="pl-mi1"><span class="pl-mi1">+</span> model_name_or_path = "merged"</span></pre></div>
<ul>
<li>è¿è¡Œ <code class="notranslate">cli_demo.py</code> ä»¥ç›®æµ‹å¾®è°ƒæ•ˆæœ</li>
</ul>
<div class="highlight highlight-source-shell"><pre class="notranslate">python ./cli_demo.py</pre></div>
<p><strong>æ•ˆæœï¼š</strong></p>
<markdown-accessiblity-table><table role="table">
<thead>
<tr>
<th>å¾®è°ƒå‰</th>
<th>å¾®è°ƒå</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="imgs/beforeFT.png"><img src="imgs/beforeFT.png" alt="O23QD48iFSZMfbr.png" style="max-width: 100%;"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="imgs/afterFT.png"><img src="imgs/afterFT.png" alt="L1sqmGgE6h2exWP.png" style="max-width: 100%;"></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p><strong><code class="notranslate">xtuner chat</code></strong> <strong>çš„å¯åŠ¨å‚æ•°</strong></p>
<markdown-accessiblity-table><table role="table">
<thead>
<tr>
<th>å¯åŠ¨å‚æ•°</th>
<th>å¹²å“ˆæ»´</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>--prompt-template</strong></td>
<td>æŒ‡å®šå¯¹è¯æ¨¡æ¿</td>
</tr>
<tr>
<td>--system</td>
<td>æŒ‡å®šSYSTEMæ–‡æœ¬</td>
</tr>
<tr>
<td>--system-template</td>
<td>æŒ‡å®šSYSTEMæ¨¡æ¿</td>
</tr>
<tr>
<td>-<strong>-bits</strong></td>
<td>LLMä½æ•°</td>
</tr>
<tr>
<td>--bot-name</td>
<td>botåç§°</td>
</tr>
<tr>
<td>--with-plugins</td>
<td>æŒ‡å®šè¦ä½¿ç”¨çš„æ’ä»¶</td>
</tr>
<tr>
<td><strong>--no-streamer</strong></td>
<td>æ˜¯å¦å¯ç”¨æµå¼ä¼ è¾“</td>
</tr>
<tr>
<td><strong>--lagent</strong></td>
<td>æ˜¯å¦ä½¿ç”¨lagent</td>
</tr>
<tr>
<td>--command-stop-word</td>
<td>å‘½ä»¤åœæ­¢è¯</td>
</tr>
<tr>
<td>--answer-stop-word</td>
<td>å›ç­”åœæ­¢è¯</td>
</tr>
<tr>
<td>--offload-folder</td>
<td>å­˜æ”¾æ¨¡å‹æƒé‡çš„æ–‡ä»¶å¤¹ï¼ˆæˆ–è€…å·²ç»å¸è½½æ¨¡å‹æƒé‡çš„æ–‡ä»¶å¤¹ï¼‰</td>
</tr>
<tr>
<td>--max-new-tokens</td>
<td>ç”Ÿæˆæ–‡æœ¬ä¸­å…è®¸çš„æœ€å¤§ <code class="notranslate">token</code> æ•°é‡</td>
</tr>
<tr>
<td><strong>--temperature</strong></td>
<td>æ¸©åº¦å€¼</td>
</tr>
<tr>
<td>--top-k</td>
<td>ä¿ç•™ç”¨äºé¡¶kç­›é€‰çš„æœ€é«˜æ¦‚ç‡è¯æ±‡æ ‡è®°æ•°</td>
</tr>
<tr>
<td>--top-p</td>
<td>å¦‚æœè®¾ç½®ä¸ºå°äº1çš„æµ®ç‚¹æ•°ï¼Œä»…ä¿ç•™æ¦‚ç‡ç›¸åŠ é«˜äº <code class="notranslate">top_p</code> çš„æœ€å°ä¸€ç»„æœ€æœ‰å¯èƒ½çš„æ ‡è®°</td>
</tr>
<tr>
<td>--seed</td>
<td>ç”¨äºå¯é‡ç°æ–‡æœ¬ç”Ÿæˆçš„éšæœºç§å­</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<h2>3 è‡ªå®šä¹‰å¾®è°ƒ</h2>
<blockquote>
<p>ä»¥ <strong><a href="https://github.com/abachaa/Medication_QA_MedInfo2019">Medication QA</a></strong> <strong>æ•°æ®é›†</strong>ä¸ºä¾‹</p>
</blockquote>
<h3>3.1 æ¦‚è¿°</h3>
<h4>3.1.1 <strong>åœºæ™¯éœ€æ±‚</strong></h4>
<p>åŸºäº InternLM-chat-7B æ¨¡å‹ï¼Œç”¨ MedQA æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œå°†å…¶å¾€<code class="notranslate">åŒ»å­¦é—®ç­”</code>é¢†åŸŸå¯¹é½ã€‚</p>
<h4>3.1.2 <strong>çœŸå®æ•°æ®é¢„è§ˆ</strong></h4>
<markdown-accessiblity-table><table role="table">
<thead>
<tr>
<th>é—®é¢˜</th>
<th>ç­”æ¡ˆ</th>
</tr>
</thead>
<tbody>
<tr>
<td>What are ketorolac eye drops?ï¼ˆä»€ä¹ˆæ˜¯é…®å’¯é…¸æ»´çœ¼æ¶²ï¼Ÿï¼‰</td>
<td>Ophthalmic   ketorolac is used to treat itchy eyes caused by allergies. It also is used to   treat swelling and redness (inflammation) that can occur after cataract   surgery. Ketorolac is in a class of medications called nonsteroidal   anti-inflammatory drugs (NSAIDs). It works by stopping the release of   substances that cause allergy symptoms and inflammation.</td>
</tr>
<tr>
<td>What medicines raise blood sugar? ï¼ˆä»€ä¹ˆè¯ç‰©ä¼šå‡é«˜è¡€ç³–ï¼Ÿï¼‰</td>
<td>Some   medicines for conditions other than diabetes can raise your blood sugar   level. This is a concern when you have diabetes. Make sure every doctor you   see knows about all of the medicines, vitamins, or herbal supplements you   take. This means anything you take with or without a prescription. Examples include:     Barbiturates.     Thiazide diuretics.     Corticosteroids.     Birth control pills (oral contraceptives) and progesterone.     Catecholamines.     Decongestants that contain beta-adrenergic agents, such as pseudoephedrine.     The B vitamin niacin. The risk of high blood sugar from niacin lowers after you have taken it for a few months. The antipsychotic medicine olanzapine (Zyprexa).</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<h3>3.2 æ•°æ®å‡†å¤‡</h3>
<blockquote>
<p><strong>ä»¥</strong> <strong><a href="https://github.com/abachaa/Medication_QA_MedInfo2019">Medication QA</a></strong> <strong>æ•°æ®é›†ä¸ºä¾‹</strong></p>
</blockquote>
<p><strong>åŸæ ¼å¼ï¼š(.xlsx)</strong></p>
<p><a target="_blank" rel="noopener noreferrer" href="imgs/medqa2019samples.png"><img src="imgs/medqa2019samples.png" alt="gjKLFUNWAx2dZDS.png" style="max-width: 100%;"></a></p>
<markdown-accessiblity-table><table role="table">
<thead>
<tr>
<th><strong>é—®é¢˜</strong></th>
<th>è¯ç‰©ç±»å‹</th>
<th>é—®é¢˜ç±»å‹</th>
<th><strong>å›ç­”</strong></th>
<th>ä¸»é¢˜</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>aaa</td>
<td>bbb</td>
<td>ccc</td>
<td>ddd</td>
<td>eee</td>
<td>fff</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<h4>3.2.1 å°†æ•°æ®è½¬ä¸º XTuner çš„æ•°æ®æ ¼å¼</h4>
<p><strong>ç›®æ ‡æ ¼å¼ï¼š(.jsonL)</strong></p>
<div class="highlight highlight-source-json"><pre class="notranslate">[{
    <span class="pl-ent">"conversation"</span>:[
        {
            <span class="pl-ent">"system"</span>: <span class="pl-s"><span class="pl-pds">"</span>xxx<span class="pl-pds">"</span></span>,
            <span class="pl-ent">"input"</span>: <span class="pl-s"><span class="pl-pds">"</span>xxx<span class="pl-pds">"</span></span>,
            <span class="pl-ent">"output"</span>: <span class="pl-s"><span class="pl-pds">"</span>xxx<span class="pl-pds">"</span></span>
        }
    ]
},
{
    <span class="pl-ent">"conversation"</span>:[
        {
            <span class="pl-ent">"system"</span>: <span class="pl-s"><span class="pl-pds">"</span>xxx<span class="pl-pds">"</span></span>,
            <span class="pl-ent">"input"</span>: <span class="pl-s"><span class="pl-pds">"</span>xxx<span class="pl-pds">"</span></span>,
            <span class="pl-ent">"output"</span>: <span class="pl-s"><span class="pl-pds">"</span>xxx<span class="pl-pds">"</span></span>
        }
    ]
}]</pre></div>
<p>ğŸ§ é€šè¿‡ pytho nè„šæœ¬ï¼šå°† <code class="notranslate">.xlsx</code> ä¸­çš„ é—®é¢˜ å’Œ å›ç­” ä¸¤åˆ— æå–å‡ºæ¥ï¼Œå†æ”¾å…¥ <code class="notranslate">.jsonL</code> æ–‡ä»¶çš„æ¯ä¸ª conversation çš„ input å’Œ output ä¸­ã€‚</p>
<blockquote>
<p>è¿™ä¸€æ­¥çš„ python è„šæœ¬å¯ä»¥è¯· ChatGPT æ¥å®Œæˆã€‚</p>
</blockquote>
<pre lang="text" class="notranslate"><code class="notranslate">Write a python file for me. using openpyxl. input file name is MedQA2019.xlsx
Step1: The input file is .xlsx. Exact the column A and column D in the sheet named "DrugQA" .
Step2: Put each value in column A into each "input" of each "conversation". Put each value in column D into each "output" of each "conversation".
Step3: The output file is .jsonL. It looks like:
[{
    "conversation":[
        {
            "system": "xxx",
            "input": "xxx",
            "output": "xxx"
        }
    ]
},
{
    "conversation":[
        {
            "system": "xxx",
            "input": "xxx",
            "output": "xxx"
        }
    ]
}]
Step4: All "system" value changes to "You are a professional, highly experienced doctor professor. You always provide accurate, comprehensive, and detailed answers based on the patients' questions."
</code></pre>
<blockquote>
<p>ChatGPT ç”Ÿæˆçš„ python ä»£ç è§æœ¬ä»“åº“çš„ <a href="./xlsx2jsonl.py">xlsx2jsonl.py</a></p>
</blockquote>
<p>æ‰§è¡Œ python è„šæœ¬ï¼Œè·å¾—æ ¼å¼åŒ–åçš„æ•°æ®é›†ï¼š</p>
<div class="highlight highlight-source-shell"><pre class="notranslate">python xlsx2jsonl.py</pre></div>
<p><strong>æ ¼å¼åŒ–åçš„æ•°æ®é›†é•¿è¿™æ ·ï¼š</strong><br>
<a target="_blank" rel="noopener noreferrer" href="imgs/dataProcessed.png"><img src="imgs/dataProcessed.png" alt="uOCJXwbfzKRWSBE.png" style="max-width: 100%;"></a></p>
<p>æ­¤æ—¶ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥å¯¹æ•°æ®è¿›è¡Œè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„åˆ†å‰²ï¼ŒåŒæ ·å¯ä»¥è®© ChatGPT å†™ python ä»£ç ã€‚å½“ç„¶å¦‚æœä½ æ²¡æœ‰ä¸¥æ ¼çš„ç§‘ç ”éœ€æ±‚ã€ä¸åœ¨ä¹â€œè®­ç»ƒé›†æ³„éœ²â€çš„é—®é¢˜ï¼Œä¹Ÿå¯ä»¥ä¸åšè®­ç»ƒé›†ä¸æµ‹è¯•é›†çš„åˆ†å‰²ã€‚</p>
<h4>3.2.2 åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†</h4>
<pre lang="text" class="notranslate"><code class="notranslate">my .jsonL file looks like:
[{
    "conversation":[
        {
            "system": "xxx",
            "input": "xxx",
            "output": "xxx"
        }
    ]
},
{
    "conversation":[
        {
            "system": "xxx",
            "input": "xxx",
            "output": "xxx"
        }
    ]
}]
Step1, read the .jsonL file.
Step2, count the amount of the "conversation" elements.
Step3, randomly split all "conversation" elements by 7:3. Targeted structure is same as the input.
Step4, save the 7/10 part as train.jsonl. save the 3/10 part as test.jsonl
</code></pre>
<p>ç”Ÿæˆçš„pythonä»£ç è§ <a href="./split2train_and_test.py">split2train_and_test.py</a></p>
<h3>3.3 å¼€å§‹è‡ªå®šä¹‰å¾®è°ƒ</h3>
<p>æ­¤æ—¶ï¼Œæˆ‘ä»¬é‡æ–°å»ºä¸€ä¸ªæ–‡ä»¶å¤¹æ¥ç©â€œå¾®è°ƒè‡ªå®šä¹‰æ•°æ®é›†â€</p>
<div class="highlight highlight-source-shell"><pre class="notranslate">mkdir <span class="pl-k">~</span>/ft-medqa <span class="pl-k">&amp;&amp;</span> <span class="pl-c1">cd</span> <span class="pl-k">~</span>/ft-medqa</pre></div>
<p>æŠŠå‰é¢ä¸‹è½½å¥½çš„internlm-chat-7bæ¨¡å‹æ–‡ä»¶å¤¹æ‹·è´è¿‡æ¥ã€‚</p>
<div class="highlight highlight-source-shell"><pre class="notranslate">cp -r <span class="pl-k">~</span>/ft-oasst1/internlm-chat-7b <span class="pl-c1">.</span></pre></div>
<p>åˆ«å¿˜äº†æŠŠè‡ªå®šä¹‰æ•°æ®é›†ï¼Œå³å‡ ä¸ª <code class="notranslate">.jsonL</code>ï¼Œä¹Ÿä¼ åˆ°æœåŠ¡å™¨ä¸Šã€‚</p>
<div class="highlight highlight-source-shell"><pre class="notranslate">git clone https://github.com/InternLM/tutorial</pre></div>
<div class="highlight highlight-source-shell"><pre class="notranslate">cp <span class="pl-k">~</span>/tutorial/xtuner/MedQA2019-structured-train.jsonl <span class="pl-c1">.</span></pre></div>
<h4>3.3.1 å‡†å¤‡é…ç½®æ–‡ä»¶</h4>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> å¤åˆ¶é…ç½®æ–‡ä»¶åˆ°å½“å‰ç›®å½•</span>
xtuner copy-cfg internlm_chat_7b_qlora_oasst1_e3 <span class="pl-c1">.</span>
<span class="pl-c"><span class="pl-c">#</span> æ”¹ä¸ªæ–‡ä»¶å</span>
mv internlm_chat_7b_qlora_oasst1_e3_copy.py internlm_chat_7b_qlora_medqa2019_e3.py

<span class="pl-c"><span class="pl-c">#</span> ä¿®æ”¹é…ç½®æ–‡ä»¶å†…å®¹</span>
vim internlm_chat_7b_qlora_medqa2019_e3.py</pre></div>
<p>å‡å·ä»£è¡¨è¦åˆ é™¤çš„è¡Œï¼ŒåŠ å·ä»£è¡¨è¦å¢åŠ çš„è¡Œã€‚</p>
<div class="highlight highlight-source-diff"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> ä¿®æ”¹importéƒ¨åˆ†</span>
<span class="pl-md"><span class="pl-md">-</span> from xtuner.dataset.map_fns import oasst1_map_fn, template_map_fn_factory</span>
<span class="pl-mi1"><span class="pl-mi1">+</span> from xtuner.dataset.map_fns import template_map_fn_factory</span>

<span class="pl-c"><span class="pl-c">#</span> ä¿®æ”¹æ¨¡å‹ä¸ºæœ¬åœ°è·¯å¾„</span>
<span class="pl-md"><span class="pl-md">-</span> pretrained_model_name_or_path = 'internlm/internlm-chat-7b'</span>
<span class="pl-mi1"><span class="pl-mi1">+</span> pretrained_model_name_or_path = './internlm-chat-7b'</span>

<span class="pl-c"><span class="pl-c">#</span> ä¿®æ”¹è®­ç»ƒæ•°æ®ä¸º MedQA2019-structured-train.jsonl è·¯å¾„</span>
<span class="pl-md"><span class="pl-md">-</span> data_path = 'timdettmers/openassistant-guanaco'</span>
<span class="pl-mi1"><span class="pl-mi1">+</span> data_path = 'MedQA2019-structured-train.jsonl'</span>

<span class="pl-c"><span class="pl-c">#</span> ä¿®æ”¹ train_dataset å¯¹è±¡</span>
train_dataset = dict(
    type=process_hf_dataset,
<span class="pl-md"><span class="pl-md">-</span>   dataset=dict(type=load_dataset, path=data_path),</span>
<span class="pl-mi1"><span class="pl-mi1">+</span>   dataset=dict(type=load_dataset, path='json', data_files=dict(train=data_path)),</span>
    tokenizer=tokenizer,
    max_length=max_length,
<span class="pl-md"><span class="pl-md">-</span>   dataset_map_fn=alpaca_map_fn,</span>
<span class="pl-mi1"><span class="pl-mi1">+</span>   dataset_map_fn=None,</span>
    template_map_fn=dict(
        type=template_map_fn_factory, template=prompt_template),
    remove_unused_columns=True,
    shuffle_before_pack=True,
    pack_to_max_length=pack_to_max_length)</pre></div>
<h4>3.3.2 <strong>XTunerï¼å¯åŠ¨ï¼</strong></h4>
<p><a target="_blank" rel="noopener noreferrer" href="imgs/ysqd.png"><img src="imgs/ysqd.png" alt="tH8udZzECYl5are.png" style="max-width: 100%;"></a></p>
<div class="highlight highlight-source-shell"><pre class="notranslate">xtuner train internlm_chat_7b_qlora_medqa2019_e3.py --deepspeed deepspeed_zero2</pre></div>
<h4>3.3.3 pth è½¬ huggingface</h4>
<p>åŒå‰è¿°ï¼Œè¿™é‡Œä¸èµ˜è¿°äº†ã€‚<a href="#236-%E5%B0%86%E5%BE%97%E5%88%B0%E7%9A%84-pth-%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%BA-huggingface-%E6%A8%A1%E5%9E%8B%E5%8D%B3%E7%94%9F%E6%88%90adapter%E6%96%87%E4%BB%B6%E5%A4%B9">å°†å¾—åˆ°çš„-pth-æ¨¡å‹è½¬æ¢ä¸º-huggingface-æ¨¡å‹å³ç”Ÿæˆadapteræ–‡ä»¶å¤¹</a></p>
<h4>3.3.4 éƒ¨ç½²ä¸æµ‹è¯•</h4>
<p>åŒå‰è¿°ã€‚<a href="#24-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%B5%8B%E8%AF%95">éƒ¨ç½²ä¸æµ‹è¯•</a></p>
<h2>4ã€è¡¥å……ã€‘ç”¨ MS-Agent æ•°æ®é›† èµ‹äºˆ LLM ä»¥ Agent èƒ½åŠ›</h2>
<h3>4.1 æ¦‚è¿°</h3>
<p>MSAgent æ•°æ®é›†æ¯æ¡æ ·æœ¬åŒ…å«ä¸€ä¸ªå¯¹è¯åˆ—è¡¨ï¼ˆconversationsï¼‰ï¼Œå…¶é‡Œé¢åŒ…å«äº† systemã€userã€assistant ä¸‰ç§å­—æ®µã€‚å…¶ä¸­ï¼š</p>
<ul>
<li>
<p>system: è¡¨ç¤ºç»™æ¨¡å‹å‰ç½®çš„äººè®¾è¾“å…¥ï¼Œå…¶ä¸­æœ‰å‘Šè¯‰æ¨¡å‹å¦‚ä½•è°ƒç”¨æ’ä»¶ä»¥åŠç”Ÿæˆè¯·æ±‚</p>
</li>
<li>
<p>user: è¡¨ç¤ºç”¨æˆ·çš„è¾“å…¥ promptï¼Œåˆ†ä¸ºä¸¤ç§ï¼Œé€šç”¨ç”Ÿæˆçš„promptå’Œè°ƒç”¨æ’ä»¶éœ€æ±‚çš„ prompt</p>
</li>
<li>
<p>assistant: ä¸ºæ¨¡å‹çš„å›å¤ã€‚å…¶ä¸­ä¼šåŒ…æ‹¬æ’ä»¶è°ƒç”¨ä»£ç å’Œæ‰§è¡Œä»£ç ï¼Œè°ƒç”¨ä»£ç æ˜¯è¦ LLM ç”Ÿæˆçš„ï¼Œè€Œæ‰§è¡Œä»£ç æ˜¯è°ƒç”¨æœåŠ¡æ¥ç”Ÿæˆç»“æœçš„</p>
</li>
</ul>
<p>ä¸€æ¡è°ƒç”¨ç½‘é¡µæœç´¢æ’ä»¶æŸ¥è¯¢â€œä¸Šæµ·æ˜å¤©å¤©æ°”â€çš„æ•°æ®æ ·æœ¬ç¤ºä¾‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š<br>
<a target="_blank" rel="noopener noreferrer" href="imgs/msagent_data.png"><img src="imgs/msagent_data.png" alt="BlgfEqpiRFO5G6L.png" style="max-width: 100%;"></a></p>
<h3>4.2 å¾®è°ƒæ­¥éª¤</h3>
<h4>4.2.1 å‡†å¤‡å·¥ä½œ</h4>
<blockquote>
<p>xtuner æ˜¯ä»å›½å†…çš„ ModelScope å¹³å°ä¸‹è½½ MS-Agent æ•°æ®é›†ï¼Œå› æ­¤ä¸ç”¨æå‰æ‰‹åŠ¨ä¸‹è½½æ•°æ®é›†æ–‡ä»¶ã€‚</p>
</blockquote>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> å‡†å¤‡å·¥ä½œ</span>
mkdir <span class="pl-k">~</span>/ft-msagent <span class="pl-k">&amp;&amp;</span> <span class="pl-c1">cd</span> <span class="pl-k">~</span>/ft-msagent
cp -r <span class="pl-k">~</span>/ft-oasst1/internlm-chat-7b <span class="pl-c1">.</span>

<span class="pl-c"><span class="pl-c">#</span> æŸ¥çœ‹é…ç½®æ–‡ä»¶</span>
xtuner list-cfg <span class="pl-k">|</span> grep msagent

<span class="pl-c"><span class="pl-c">#</span> å¤åˆ¶é…ç½®æ–‡ä»¶åˆ°å½“å‰ç›®å½•</span>
xtuner copy-cfg internlm_7b_qlora_msagent_react_e3_gpu8 <span class="pl-c1">.</span>

<span class="pl-c"><span class="pl-c">#</span> ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹ä¸ºæœ¬åœ°è·¯å¾„</span>
vim ./internlm_7b_qlora_msagent_react_e3_gpu8_copy.py </pre></div>
<div class="highlight highlight-source-diff"><pre class="notranslate"><span class="pl-md"><span class="pl-md">-</span> pretrained_model_name_or_path = 'internlm/internlm-chat-7b'</span>
<span class="pl-mi1"><span class="pl-mi1">+</span> pretrained_model_name_or_path = './internlm-chat-7b'</span></pre></div>
<h4>4.2.2 å¼€å§‹å¾®è°ƒ</h4>
<div class="highlight highlight-source-shell"><pre class="notranslate">xtuner train ./internlm_7b_qlora_msagent_react_e3_gpu8_copy.py --deepspeed deepspeed_zero2</pre></div>
<h3>4.3 ç›´æ¥ä½¿ç”¨</h3>
<blockquote>
<p>ç”±äº msagent çš„è®­ç»ƒéå¸¸è´¹æ—¶ï¼Œå¤§å®¶å¦‚æœæƒ³å°½å¿«æŠŠè¿™ä¸ªæ•™ç¨‹è·Ÿå®Œï¼Œå¯ä»¥ç›´æ¥ä» modelScope æ‹‰å–å’±ä»¬å·²ç»å¾®è°ƒå¥½äº†çš„ Adapterã€‚å¦‚ä¸‹æ¼”ç¤ºã€‚</p>
</blockquote>
<h4>4.3.1 ä¸‹è½½ Adapter</h4>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c1">cd</span> <span class="pl-k">~</span>/ft-msagent
apt install git git-lfs
git lfs install
git lfs clone https://www.modelscope.cn/xtuner/internlm-7b-qlora-msagent-react.git</pre></div>
<p>OKï¼Œç°åœ¨ç›®å½•åº”è¯¥é•¿è¿™æ ·ï¼š</p>
<ul>
<li>internlm_7b_qlora_msagent_react_e3_gpu8_copy.py</li>
<li>internlm-7b-qlora-msagent-react</li>
<li>internlm-chat-7b</li>
<li>work_dirï¼ˆå¯æœ‰å¯æ— ï¼‰</li>
</ul>
<p>æœ‰äº†è¿™ä¸ªåœ¨ msagent ä¸Šè®­ç»ƒå¾—åˆ°çš„Adapterï¼Œæ¨¡å‹ç°åœ¨å·²ç»æœ‰ agent èƒ½åŠ›äº†ï¼å°±å¯ä»¥åŠ  --lagent ä»¥è°ƒç”¨æ¥è‡ª lagent çš„ä»£ç†åŠŸèƒ½äº†ï¼</p>
<h4>4.3.2 æ·»åŠ  serper ç¯å¢ƒå˜é‡</h4>
<blockquote>
<p><strong>å¼€å§‹ chat ä¹‹å‰ï¼Œè¿˜è¦åŠ ä¸ª serper çš„ç¯å¢ƒå˜é‡ï¼š</strong></p>
<p>å» serper.dev å…è´¹æ³¨å†Œä¸€ä¸ªè´¦å·ï¼Œç”Ÿæˆè‡ªå·±çš„ api keyã€‚è¿™ä¸ªä¸œè¥¿æ˜¯ç”¨æ¥ç»™ lagent å»è·å– google æœç´¢çš„ç»“æœçš„ã€‚ç­‰äºæ˜¯ serper.dev å¸®ä½ å»è®¿é—® googleï¼Œè€Œä¸æ˜¯ä»ä½ è‡ªå·±æœ¬åœ°å»è®¿é—® google äº†ã€‚</p>
</blockquote>
<p><a target="_blank" rel="noopener noreferrer" href="imgs/serper.png"><img src="imgs/serper.png" alt="kDSdpQrhHfTWYsc.png" style="max-width: 100%;"></a></p>
<p>æ·»åŠ  serper api key åˆ°ç¯å¢ƒå˜é‡ï¼š</p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-k">export</span> SERPER_API_KEY=abcdefg</pre></div>
<h4>4.3.3 xtuner + agentï¼Œå¯åŠ¨ï¼</h4>
<div class="highlight highlight-source-shell"><pre class="notranslate">xtuner chat ./internlm-chat-7b --adapter internlm-7b-qlora-msagent-react --lagent</pre></div>
<h4>4.3.4 æŠ¥é”™å¤„ç†</h4>
<p>xtuner chat å¢åŠ  --lagent å‚æ•°åï¼ŒæŠ¥é”™ <code class="notranslate">TypeError: transfomers.modelsauto.auto factory. BaseAutoModelClass.from pretrained() got multiple values for keyword argument "trust remote code"</code></p>
<p>æ³¨é‡Šæ‰å·²å®‰è£…åŒ…ä¸­çš„ä»£ç ï¼š</p>
<div class="highlight highlight-source-shell"><pre class="notranslate">vim /root/xtuner019/xtuner/xtuner/tools/chat.py</pre></div>
<p><a target="_blank" rel="noopener noreferrer" href="imgs/bugfix1.png"><img src="imgs/bugfix1.png" alt="NfHAV1b4zqYv5kR.png" style="max-width: 100%;"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="imgs/bugfix2.png"><img src="imgs/bugfix2.png" alt="YTpz1qemiojk5Bg.png" style="max-width: 100%;"></a></p>
<h2>5 å…¶ä»–å·²çŸ¥é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆï¼š</h2>
<p><a href="https://docs.qq.com/doc/DY1d2ZVFlbXlrUERj" rel="nofollow">https://docs.qq.com/doc/DY1d2ZVFlbXlrUERj</a></p>
<p>å°ä½œä¸šåŠ©æ•™è€å¸ˆä¼šåœ¨ç¤¾ç¾¤ä¸­å…¬å¸ƒã€‚<br>
Have fun!</p>
<h2>6 æ³¨æ„äº‹é¡¹</h2>
<p>æœ¬æ•™ç¨‹ä½¿ç”¨ xtuner 0.1.9 ç‰ˆæœ¬<br>
è‹¥éœ€è¦è·Ÿç€æœ¬æ•™ç¨‹ä¸€æ­¥ä¸€æ­¥å®Œæˆï¼Œå»ºè®®ä¸¥æ ¼éµå¾ªæœ¬æ•™ç¨‹çš„æ­¥éª¤ï¼</p>
<p>è‹¥å‡ºç°è«åå…¶å¦™æŠ¥é”™ï¼Œè¯·å°è¯•æ›´æ¢ä¸ºä»¥ä¸‹åŒ…çš„ç‰ˆæœ¬ï¼šï¼ˆå¦‚æœæœ‰æŠ¥é”™å†æ£€æŸ¥ï¼Œæ²¡æŠ¥é”™ä¸ç”¨çœ‹ï¼‰</p>
<pre class="notranslate"><code class="notranslate">torch                         2.1.1
transformers                  4.34.0
transformers-stream-generator 0.0.4
</code></pre>
<div class="highlight highlight-source-shell"><pre class="notranslate">pip install torch==2.1.1
pip install transformers==4.34.0
pip install transformers-stream-generator=0.0.4</pre></div>
<p>CUDA ç›¸å…³ï¼šï¼ˆå¦‚æœæœ‰æŠ¥é”™å†æ£€æŸ¥ï¼Œæ²¡æŠ¥é”™ä¸ç”¨çœ‹ï¼‰</p>
<pre class="notranslate"><code class="notranslate">NVIDIA-SMI 535.54.03              
Driver Version: 535.54.03    
CUDA Version: 12.2

nvidia-cuda-cupti-cu12        12.1.105
nvidia-cuda-nvrtc-cu12        12.1.105
nvidia-cuda-runtime-cu12      12.1.105
</code></pre>
<h2>7 ä½œä¸š</h2>
<p><strong>åŸºç¡€ä½œä¸šï¼š</strong></p>
<p>æ„å»ºæ•°æ®é›†ï¼Œä½¿ç”¨ XTuner å¾®è°ƒ InternLM-Chat-7B æ¨¡å‹, è®©æ¨¡å‹å­¦ä¹ åˆ°å®ƒæ˜¯ä½ çš„æ™ºèƒ½å°åŠ©æ‰‹ï¼Œæ•ˆæœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæœ¬ä½œä¸šè®­ç»ƒå‡ºæ¥çš„æ¨¡å‹çš„è¾“å‡ºéœ€è¦<strong>å°†ä¸è¦è‘±å§œè’œå¤§ä½¬</strong>æ›¿æ¢æˆè‡ªå·±åå­—æˆ–æ˜µç§°ï¼</p>
<p><strong>å¾®è°ƒå‰</strong>ï¼ˆå›ç­”æ¯”è¾ƒå®˜æ–¹ï¼‰</p>
<p><strong>å¾®è°ƒå</strong>ï¼ˆå¯¹è‡ªå·±çš„èº«ä»½æœ‰äº†æ¸…æ™°çš„è®¤çŸ¥ï¼‰<br>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/mattheliu/gitblog/assets/102272920/4acb5bd6-35dc-4d2a-b422-2a102888dca6"><img src="https://github.com/mattheliu/gitblog/assets/102272920/4acb5bd6-35dc-4d2a-b422-2a102888dca6" alt="Pasted image 20240125160938" style="max-width: 100%;"></a></p>
<p>ä½œä¸šå‚è€ƒç­”æ¡ˆï¼š<a href="https://github.com/InternLM/tutorial/blob/main/xtuner/self.md">https://github.com/InternLM/tutorial/blob/main/xtuner/self.md</a></p>
<p><strong>è¿›é˜¶ä½œä¸šï¼š</strong></p>
<ul>
<li>å°†è®­ç»ƒå¥½çš„Adapteræ¨¡å‹æƒé‡ä¸Šä¼ åˆ° OpenXLabã€Hugging Face æˆ–è€… MoelScope ä»»ä¸€ä¸€å¹³å°ã€‚<br>
<a href="https://openxlab.org.cn/models/detail/leonliuzx/xiamu-model" rel="nofollow">xiamu-model</a></li>
<li>å°†è®­ç»ƒå¥½åçš„æ¨¡å‹åº”ç”¨éƒ¨ç½²åˆ° OpenXLab å¹³å°ï¼Œå‚è€ƒéƒ¨ç½²æ–‡æ¡£è¯·è®¿é—®ï¼š<a href="https://aicarrier.feishu.cn/docx/MQH6dygcKolG37x0ekcc4oZhnCe" rel="nofollow">https://aicarrier.feishu.cn/docx/MQH6dygcKolG37x0ekcc4oZhnCe</a></li>
</ul>
<p><strong>æ•´ä½“å®è®­è¥é¡¹ç›®ï¼š</strong></p>
<p>æ—¶é—´å‘¨æœŸï¼šå³æ—¥èµ·è‡´è¯¾ç¨‹ç»“æŸ</p>
<p>å³æ—¥å¼€å§‹å¯ä»¥åœ¨ç­çº§ç¾¤ä¸­éšæœºç»„é˜Ÿå®Œæˆä¸€ä¸ªå¤§ä½œä¸šé¡¹ç›®ï¼Œä¸€äº›å¯æä¾›çš„é€‰é¢˜å¦‚ä¸‹ï¼š</p>
<ul>
<li>äººæƒ…ä¸–æ•…å¤§æ¨¡å‹ï¼šä¸€ä¸ªå¸®åŠ©ç”¨æˆ·æ’°å†™æ–°å¹´ç¥ç¦æ–‡æ¡ˆçš„äººæƒ…äº‹æ•…å¤§æ¨¡å‹</li>
<li>ä¸­å°å­¦æ•°å­¦å¤§æ¨¡å‹ï¼šä¸€ä¸ªæ‹¥æœ‰ä¸€å®šæ•°å­¦è§£é¢˜èƒ½åŠ›çš„å¤§æ¨¡å‹</li>
<li>å¿ƒç†å¤§æ¨¡å‹ï¼šä¸€ä¸ªæ²»æ„ˆçš„å¿ƒç†å¤§æ¨¡å‹</li>
<li>å·¥å…·è°ƒç”¨ç±»é¡¹ç›®ï¼šç»“åˆ Lagent æ„å»ºæ•°æ®é›†è®­ç»ƒ InternLM æ¨¡å‹ï¼Œæ”¯æŒå¯¹ MMYOLO ç­‰å·¥å…·çš„è°ƒç”¨</li>
</ul>
<p>å…¶ä»–åŸºäºä¹¦ç”ŸÂ·æµ¦è¯­å·¥å…·é“¾çš„å°é¡¹ç›®éƒ½åœ¨èŒƒå›´å†…ï¼Œæ¬¢è¿å¤§å®¶å……åˆ†å‘æŒ¥æƒ³è±¡åŠ›ã€‚</p>
</div>
<div style="font-size:small;margin-top:8px;float:right;"></div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">è¯„è®º</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright Â© <span id="copyrightYear"></span> <a href="https://mattheliu.github.io">Leonliuzx-Blog</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if(""!=""){
    var startSite=new Date("");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="ç½‘ç«™è¿è¡Œ"+diffDay+"å¤©"+" â€¢ ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z', 'copy': 'M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z', 'check': 'M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","mattheliu/mattheliu.github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}

document.addEventListener('DOMContentLoaded', () => {
    const createClipboardHTML = (codeContent, additionalClasses = '') => `
        <pre class="notranslate"><code class="notranslate">${codeContent}</code></pre>
        <div class="clipboard-container position-absolute right-0 top-0 ${additionalClasses}">
            <clipboard-copy class="ClipboardButton btn m-2 p-0" role="button" style="display: inherit;">
                <svg height="16" width="16" class="octicon octicon-copy m-2"><path d="${IconList["copy"]}"></path></svg>
                <svg height="16" width="16" class="octicon octicon-check color-fg-success m-2 d-none"><path d="${IconList["check"]}"></path></svg>
            </clipboard-copy>
            <div class="copy-feedback">Copied!</div>
        </div>
    `;

    const handleCodeElements = (selector = '') => {
        document.querySelectorAll(selector).forEach(codeElement => {
            const codeContent = codeElement.innerHTML;
            const newStructure = document.createElement('div');
            newStructure.className = 'snippet-clipboard-content position-relative overflow-auto';
            newStructure.innerHTML = createClipboardHTML(codeContent);

            const parentElement = codeElement.parentElement;
            if (selector.includes('highlight')) {
                parentElement.insertBefore(newStructure, codeElement.nextSibling);
                parentElement.removeChild(codeElement);
            } else {
                parentElement.parentElement.replaceChild(newStructure, parentElement);
            }
        });
    };

    handleCodeElements('pre.notranslate > code.notranslate');
    handleCodeElements('div.highlight > pre.notranslate');

    let currentFeedback = null;
    document.querySelectorAll('clipboard-copy').forEach(copyButton => {
        copyButton.addEventListener('click', () => {
            const codeContent = copyButton.closest('.snippet-clipboard-content').innerText;
            const tempTextArea = document.createElement('textarea');
            tempTextArea.value = codeContent;
            document.body.appendChild(tempTextArea);
            tempTextArea.select();
            document.execCommand('copy');
            document.body.removeChild(tempTextArea);

            const copyIcon = copyButton.querySelector('.octicon-copy');
            const checkIcon = copyButton.querySelector('.octicon-check');
            const copyFeedback = copyButton.nextElementSibling;

            if (currentFeedback && currentFeedback !== copyFeedback) {currentFeedback.style.display = 'none';}
            currentFeedback = copyFeedback;

            copyIcon.classList.add('d-none');
            checkIcon.classList.remove('d-none');
            copyFeedback.style.display = 'block';
            copyButton.style.borderColor = 'var(--color-success-fg)';

            setTimeout(() => {
                copyIcon.classList.remove('d-none');
                checkIcon.classList.add('d-none');
                copyFeedback.style.display = 'none';
                copyButton.style.borderColor = '';
            }, 2000);
        });
    });
});

</script>


</html>
